comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  3.12ba/s]100%|██████████| 1/1 [00:00<00:00,  3.12ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  3.40ba/s]100%|██████████| 1/1 [00:00<00:00,  3.40ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  9.46ba/s]100%|██████████| 1/1 [00:00<00:00,  9.43ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  9.25ba/s]100%|██████████| 1/1 [00:00<00:00,  9.23ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  7.75ba/s]100%|██████████| 1/1 [00:00<00:00,  7.73ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  6.66ba/s]100%|██████████| 1/1 [00:00<00:00,  6.65ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  7.52ba/s]100%|██████████| 1/1 [00:00<00:00,  7.50ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  5.90ba/s]100%|██████████| 1/1 [00:00<00:00,  5.89ba/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 357
  Batch size = 16
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
  0%|          | 0/23 [00:00<?, ?it/s] 22%|██▏       | 5/23 [00:00<00:00, 42.11it/s] 43%|████▎     | 10/23 [00:00<00:00, 37.22it/s] 61%|██████    | 14/23 [00:00<00:00, 31.02it/s] 78%|███████▊  | 18/23 [00:00<00:00, 33.07it/s] 96%|█████████▌| 22/23 [00:00<00:00, 34.49it/s]100%|██████████| 23/23 [00:00<00:00, 35.14it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 360
  Batch size = 16
357
357
{'eval_kappa': 0.7726576408727694, 'eval_loss': 0.7914560437202454, 'eval_runtime': 1.2492, 'eval_samples_per_second': 285.782, 'eval_steps_per_second': 18.412}
[0, 1, 2, 3, 4, 5, 6]
  0%|          | 0/23 [00:00<?, ?it/s] 22%|██▏       | 5/23 [00:00<00:00, 46.76it/s] 43%|████▎     | 10/23 [00:00<00:00, 40.89it/s] 65%|██████▌   | 15/23 [00:00<00:00, 39.31it/s] 83%|████████▎ | 19/23 [00:00<00:00, 38.71it/s]100%|██████████| 23/23 [00:00<00:00, 39.84it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 345
  Batch size = 16
360
360
{'eval_kappa': 0.5685913455215047, 'eval_loss': 0.3765983581542969, 'eval_runtime': 0.6032, 'eval_samples_per_second': 596.834, 'eval_steps_per_second': 38.131}
[0, 1, 2, 3]
  0%|          | 0/22 [00:00<?, ?it/s] 32%|███▏      | 7/22 [00:00<00:00, 62.81it/s] 64%|██████▎   | 14/22 [00:00<00:00, 57.40it/s] 91%|█████████ | 20/22 [00:00<00:00, 55.97it/s]100%|██████████| 22/22 [00:00<00:00, 57.04it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 354
  Batch size = 16
345
345
{'eval_kappa': 0.5522210155484333, 'eval_loss': 0.4881019592285156, 'eval_runtime': 0.4016, 'eval_samples_per_second': 859.055, 'eval_steps_per_second': 54.78}
[0, 1, 2, 3]
  0%|          | 0/23 [00:00<?, ?it/s] 26%|██▌       | 6/23 [00:00<00:00, 49.43it/s] 48%|████▊     | 11/23 [00:00<00:00, 44.10it/s] 70%|██████▉   | 16/23 [00:00<00:00, 42.78it/s] 91%|█████████▏| 21/23 [00:00<00:00, 42.16it/s]100%|██████████| 23/23 [00:00<00:00, 44.23it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 361
  Batch size = 16
354
354
{'eval_kappa': 0.7692238258096222, 'eval_loss': 0.28872281312942505, 'eval_runtime': 0.5435, 'eval_samples_per_second': 651.297, 'eval_steps_per_second': 42.316}
[0, 1, 2, 3, 4]
  0%|          | 0/23 [00:00<?, ?it/s] 22%|██▏       | 5/23 [00:00<00:00, 49.14it/s] 43%|████▎     | 10/23 [00:00<00:00, 42.89it/s] 65%|██████▌   | 15/23 [00:00<00:00, 41.21it/s] 87%|████████▋ | 20/23 [00:00<00:00, 40.47it/s]100%|██████████| 23/23 [00:00<00:00, 41.69it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 360
  Batch size = 16
361
361
{'eval_kappa': 0.7902508450453656, 'eval_loss': 0.27907994389533997, 'eval_runtime': 0.5749, 'eval_samples_per_second': 627.897, 'eval_steps_per_second': 40.005}
[0, 1, 2, 3, 4]
  0%|          | 0/23 [00:00<?, ?it/s] 22%|██▏       | 5/23 [00:00<00:00, 46.72it/s] 43%|████▎     | 10/23 [00:00<00:00, 40.86it/s] 65%|██████▌   | 15/23 [00:00<00:00, 39.41it/s] 83%|████████▎ | 19/23 [00:00<00:00, 38.80it/s]100%|██████████| 23/23 [00:00<00:00, 39.95it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 314
  Batch size = 16
360
360
{'eval_kappa': 0.8296100644032622, 'eval_loss': 0.23798947036266327, 'eval_runtime': 0.6012, 'eval_samples_per_second': 598.83, 'eval_steps_per_second': 38.259}
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
  0%|          | 0/20 [00:00<?, ?it/s] 25%|██▌       | 5/20 [00:00<00:00, 49.02it/s] 50%|█████     | 10/20 [00:00<00:00, 42.83it/s] 75%|███████▌  | 15/20 [00:00<00:00, 41.15it/s]100%|██████████| 20/20 [00:00<00:00, 41.57it/s]100%|██████████| 20/20 [00:00<00:00, 41.78it/s]
The following columns in the evaluation set  don't have a corresponding argument in `FakeNewsClassifierModel.forward` and have been ignored: essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3. If essay_id, rater1_domain1, rater3_trait1, rater2_domain2, rater3_trait5, rater1_trait5, rater1_trait4, rater3_domain1, essay_set, rater1_domain2, rater2_trait3, rater2_trait6, essay, rater2_trait4, rater1_trait6, rater3_trait4, Unnamed: 0, rater2_trait5, rater3_trait2, rater3_trait3, token_type_ids, __index_level_0__, domain2_score, rater3_trait6, rater2_domain1, rater2_trait1, rater2_trait2, rater1_trait2, rater1_trait1, rater1_trait3 are not expected by `FakeNewsClassifierModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 145
  Batch size = 16
314
314
{'eval_kappa': 0.8190108672458074, 'eval_loss': 7.133749485015869, 'eval_runtime': 0.5016, 'eval_samples_per_second': 625.94, 'eval_steps_per_second': 39.869}
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]
  0%|          | 0/10 [00:00<?, ?it/s] 50%|█████     | 5/10 [00:00<00:00, 46.87it/s]100%|██████████| 10/10 [00:00<00:00, 45.61it/s]100%|██████████| 10/10 [00:00<00:00, 45.22it/s]
145
145
{'eval_kappa': 0.7172729265309681, 'eval_loss': 16.306726455688477, 'eval_runtime': 0.2467, 'eval_samples_per_second': 587.73, 'eval_steps_per_second': 40.533}
Average eval_Kappa:  0.7273548163722166
