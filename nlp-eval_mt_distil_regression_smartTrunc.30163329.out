comet_ml is installed but `COMET_API_KEY` is not set.
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  2.31ba/s]
100%|██████████| 1/1 [00:00<00:00,  2.31ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  2.32ba/s]
100%|██████████| 1/1 [00:00<00:00,  2.32ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  5.63ba/s]
100%|██████████| 1/1 [00:00<00:00,  5.62ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  5.45ba/s]
100%|██████████| 1/1 [00:00<00:00,  5.44ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  4.75ba/s]
100%|██████████| 1/1 [00:00<00:00,  4.75ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  3.96ba/s]
100%|██████████| 1/1 [00:00<00:00,  3.96ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  4.45ba/s]
100%|██████████| 1/1 [00:00<00:00,  4.45ba/s]

  0%|          | 0/1 [00:00<?, ?ba/s]
100%|██████████| 1/1 [00:00<00:00,  5.19ba/s]
100%|██████████| 1/1 [00:00<00:00,  5.18ba/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 357
  Batch size = 16

  0%|          | 0/23 [00:00<?, ?it/s]
  9%|▊         | 2/23 [00:00<00:01, 18.16it/s]
 17%|█▋        | 4/23 [00:00<00:01, 12.64it/s]
 26%|██▌       | 6/23 [00:00<00:01, 11.58it/s]
 35%|███▍      | 8/23 [00:00<00:01, 11.15it/s]
 43%|████▎     | 10/23 [00:00<00:01, 10.94it/s]
 52%|█████▏    | 12/23 [00:01<00:01, 10.81it/s]
 61%|██████    | 14/23 [00:01<00:01,  8.85it/s]
 70%|██████▉   | 16/23 [00:01<00:00,  9.33it/s]
 78%|███████▊  | 18/23 [00:01<00:00,  9.68it/s]
 87%|████████▋ | 20/23 [00:01<00:00,  9.94it/s]
 96%|█████████▌| 22/23 [00:02<00:00, 10.14it/s]
100%|██████████| 23/23 [00:02<00:00, 10.29it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 360
  Batch size = 16
{'eval_kappa': 0.7223781576932891, 'eval_loss': 0.9579058885574341, 'eval_runtime': 4.7144, 'eval_samples_per_second': 75.726, 'eval_steps_per_second': 4.879}

  0%|          | 0/23 [00:00<?, ?it/s]
 13%|█▎        | 3/23 [00:00<00:01, 15.62it/s]
 22%|██▏       | 5/23 [00:00<00:01, 12.55it/s]
 30%|███       | 7/23 [00:00<00:01, 11.55it/s]
 39%|███▉      | 9/23 [00:00<00:01, 11.10it/s]
 48%|████▊     | 11/23 [00:00<00:01, 10.85it/s]
 57%|█████▋    | 13/23 [00:01<00:00, 10.69it/s]
 65%|██████▌   | 15/23 [00:01<00:00, 10.58it/s]
 74%|███████▍  | 17/23 [00:01<00:00, 10.54it/s]
 83%|████████▎ | 19/23 [00:01<00:00, 10.49it/s]
 91%|█████████▏| 21/23 [00:01<00:00, 10.45it/s]
100%|██████████| 23/23 [00:02<00:00, 11.26it/s]
100%|██████████| 23/23 [00:02<00:00, 11.08it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 345
  Batch size = 16
{'eval_kappa': 0.6169088507265521, 'eval_loss': 0.31830382347106934, 'eval_runtime': 2.1798, 'eval_samples_per_second': 165.152, 'eval_steps_per_second': 10.551}

  0%|          | 0/22 [00:00<?, ?it/s]
 14%|█▎        | 3/22 [00:00<00:00, 23.35it/s]
 27%|██▋       | 6/22 [00:00<00:00, 18.04it/s]
 36%|███▋      | 8/22 [00:00<00:00, 17.04it/s]
 45%|████▌     | 10/22 [00:00<00:00, 16.46it/s]
 55%|█████▍    | 12/22 [00:00<00:00, 16.13it/s]
 64%|██████▎   | 14/22 [00:00<00:00, 15.93it/s]
 73%|███████▎  | 16/22 [00:00<00:00, 15.78it/s]
 82%|████████▏ | 18/22 [00:01<00:00, 15.72it/s]
 91%|█████████ | 20/22 [00:01<00:00, 15.66it/s]
100%|██████████| 22/22 [00:01<00:00, 16.70it/s]
100%|██████████| 22/22 [00:01<00:00, 16.52it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 354
  Batch size = 16
{'eval_kappa': 0.544137713865855, 'eval_loss': 0.5204643607139587, 'eval_runtime': 1.3939, 'eval_samples_per_second': 247.502, 'eval_steps_per_second': 15.783}

  0%|          | 0/23 [00:00<?, ?it/s]
 13%|█▎        | 3/23 [00:00<00:01, 17.84it/s]
 22%|██▏       | 5/23 [00:00<00:01, 14.28it/s]
 30%|███       | 7/23 [00:00<00:01, 13.14it/s]
 39%|███▉      | 9/23 [00:00<00:01, 12.61it/s]
 48%|████▊     | 11/23 [00:00<00:00, 12.32it/s]
 57%|█████▋    | 13/23 [00:01<00:00, 12.16it/s]
 65%|██████▌   | 15/23 [00:01<00:00, 12.05it/s]
 74%|███████▍  | 17/23 [00:01<00:00, 11.98it/s]
 83%|████████▎ | 19/23 [00:01<00:00, 11.92it/s]
 91%|█████████▏| 21/23 [00:01<00:00, 11.88it/s]
100%|██████████| 23/23 [00:01<00:00, 12.80it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 361
  Batch size = 16
{'eval_kappa': 0.7676955907547113, 'eval_loss': 0.2925730347633362, 'eval_runtime': 1.8782, 'eval_samples_per_second': 188.476, 'eval_steps_per_second': 12.246}

  0%|          | 0/23 [00:00<?, ?it/s]
 13%|█▎        | 3/23 [00:00<00:00, 20.37it/s]
 26%|██▌       | 6/23 [00:00<00:01, 15.81it/s]
 35%|███▍      | 8/23 [00:00<00:01, 14.97it/s]
 43%|████▎     | 10/23 [00:00<00:00, 14.50it/s]
 52%|█████▏    | 12/23 [00:00<00:00, 14.20it/s]
 61%|██████    | 14/23 [00:00<00:00, 13.99it/s]
 70%|██████▉   | 16/23 [00:01<00:00, 13.86it/s]
 78%|███████▊  | 18/23 [00:01<00:00, 13.79it/s]
 87%|████████▋ | 20/23 [00:01<00:00, 13.74it/s]
 96%|█████████▌| 22/23 [00:01<00:00, 13.68it/s]
100%|██████████| 23/23 [00:01<00:00, 14.43it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 360
  Batch size = 16
{'eval_kappa': 0.7713845559602783, 'eval_loss': 0.29727232456207275, 'eval_runtime': 1.6665, 'eval_samples_per_second': 216.615, 'eval_steps_per_second': 13.801}

  0%|          | 0/23 [00:00<?, ?it/s]
 13%|█▎        | 3/23 [00:00<00:01, 16.23it/s]
 22%|██▏       | 5/23 [00:00<00:01, 13.03it/s]
 30%|███       | 7/23 [00:00<00:01, 11.99it/s]
 39%|███▉      | 9/23 [00:00<00:01, 11.53it/s]
 48%|████▊     | 11/23 [00:00<00:01, 11.29it/s]
 57%|█████▋    | 13/23 [00:01<00:00, 11.13it/s]
 65%|██████▌   | 15/23 [00:01<00:00, 11.03it/s]
 74%|███████▍  | 17/23 [00:01<00:00, 10.95it/s]
 83%|████████▎ | 19/23 [00:01<00:00, 10.91it/s]
 91%|█████████▏| 21/23 [00:01<00:00, 10.89it/s]
100%|██████████| 23/23 [00:01<00:00, 11.73it/s]
100%|██████████| 23/23 [00:01<00:00, 11.53it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 314
  Batch size = 16
{'eval_kappa': 0.821005076978439, 'eval_loss': 0.26798227429389954, 'eval_runtime': 2.0847, 'eval_samples_per_second': 172.687, 'eval_steps_per_second': 11.033}

  0%|          | 0/20 [00:00<?, ?it/s]
 15%|█▌        | 3/20 [00:00<00:01, 15.93it/s]
 25%|██▌       | 5/20 [00:00<00:01, 12.92it/s]
 35%|███▌      | 7/20 [00:00<00:01, 11.93it/s]
 45%|████▌     | 9/20 [00:00<00:00, 11.49it/s]
 55%|█████▌    | 11/20 [00:00<00:00, 11.20it/s]
 65%|██████▌   | 13/20 [00:01<00:00, 11.04it/s]
 75%|███████▌  | 15/20 [00:01<00:00, 10.93it/s]
 85%|████████▌ | 17/20 [00:01<00:00, 10.87it/s]
 95%|█████████▌| 19/20 [00:01<00:00, 10.85it/s]
100%|██████████| 20/20 [00:01<00:00, 11.50it/s]
The following columns in the evaluation set  don't have a corresponding argument in `EssayScorerModel.forward` and have been ignored: domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3. If domain2_score, rater1_trait1, token_type_ids, rater3_trait1, essay_set, essay_id, rater2_trait4, rater1_trait5, rater2_trait5, rater2_trait1, rater3_trait2, rater3_trait4, rater3_trait6, rater2_domain2, rater1_domain2, rater2_trait3, rater1_trait2, rater1_domain1, rater2_trait2, rater3_domain1, rater2_domain1, rater2_trait6, rater1_trait6, rater3_trait5, __index_level_0__, Unnamed: 0, rater3_trait3, rater1_trait4, essay, rater1_trait3 are not expected by `EssayScorerModel.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 145
  Batch size = 16
{'eval_kappa': 0.821799284985492, 'eval_loss': 6.830715656280518, 'eval_runtime': 1.8325, 'eval_samples_per_second': 171.354, 'eval_steps_per_second': 10.914}

  0%|          | 0/10 [00:00<?, ?it/s]
 30%|███       | 3/10 [00:00<00:00, 16.03it/s]
 50%|█████     | 5/10 [00:00<00:00, 12.87it/s]
 70%|███████   | 7/10 [00:00<00:00, 11.85it/s]
 90%|█████████ | 9/10 [00:00<00:00, 11.41it/s]
100%|██████████| 10/10 [00:00<00:00, 13.06it/s]
{'eval_kappa': 0.7656030608673262, 'eval_loss': 13.707365036010742, 'eval_runtime': 0.8554, 'eval_samples_per_second': 169.509, 'eval_steps_per_second': 11.69}
Average eval_Kappa:  0.7288640364789929
